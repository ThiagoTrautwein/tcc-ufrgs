{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCC - Análise de Sinais EEG\n",
    "\n",
    "Este notebook apresenta um fluxo de trabalho completo para a análise de sinais de EEG, desde a leitura e pré-processamento dos dados até a construção, treinamento e avaliação de um modelo de aprendizado profundo para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bibliotecas e Configurações Iniciais\n",
    "\n",
    "Importação das bibliotecas necessárias e configuração do ambiente, incluindo a alocação de memória da GPU, se disponível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 07:50:03.083715: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-22 07:50:03.175880: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-22 07:50:04.421219: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pywt\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Configuração da GPU (opcional)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "DATALAKE_DIR = '/home/thiago/gdrive/UFRGS/TCC/tcc-ufrgs/datalake'\n",
    "RAW_MUSE_PATH = f'{DATALAKE_DIR}/raw/Muse-v1.0/MU.txt'\n",
    "CSV_MUSE_PATH = f'{DATALAKE_DIR}/raw/Muse-v1.0/MU.csv'\n",
    "PREPROCESSED_MUSE_PATH = f'{DATALAKE_DIR}/processed/Muse-v1.0/MU_filtered.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Leitura e Preparação dos Dados\n",
    "\n",
    "Esta seção é responsável por carregar os dados brutos, convertê-los para um formato CSV mais estruturado e, em seguida, realizar a leitura para o pré-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo CSV já existe em: /home/thiago/gdrive/UFRGS/TCC/tcc-ufrgs/datalake/raw/Muse-v1.0/MU.csv\n"
     ]
    }
   ],
   "source": [
    "def generate_muse_v1_csv(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Converte o arquivo de dados brutos (formato .txt) para um arquivo CSV.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_path):\n",
    "        col_names = [\"id\", \"event\", \"device\", \"channel\", \"code\", \"size\", \"data\"]\n",
    "        df = pd.read_csv(input_path, header=None, sep='\\t', names=col_names)\n",
    "        df.to_csv(output_path, index=False, sep=';')\n",
    "        print(f\"Arquivo CSV gerado em: {output_path}\")\n",
    "    else:\n",
    "        print(f\"Arquivo CSV já existe em: {output_path}\")\n",
    "\n",
    "# Gerar o CSV a partir do arquivo .txt\n",
    "generate_muse_v1_csv(RAW_MUSE_PATH, CSV_MUSE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento e Filtragem dos Sinais\n",
    "\n",
    "Aplicação de filtros para remover ruídos e artefatos dos sinais de EEG. As seguintes técnicas são utilizadas:\n",
    "- **Filtro Butterworth Passa-Alta:** Para remover a flutuação da linha de base.\n",
    "- **Filtro Notch:** Para remover a interferência da rede elétrica (60 Hz).\n",
    "- **Denoising com Transformada Wavelet Discreta (DWT):** Para atenuar ruídos de alta frequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo pré-processado já existe em: /home/thiago/gdrive/UFRGS/TCC/tcc-ufrgs/datalake/processed/Muse-v1.0/MU_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "class Preprocessing:\n",
    "    def butterworth_highpass(self, data, cutoff, fs, order):\n",
    "        b, a = butter(order, cutoff / (fs / 2), btype=\"high\", analog=False)\n",
    "        return filtfilt(b, a, data)\n",
    "\n",
    "    def notch_filter(self, data, fs, freq, Q):\n",
    "        b, a = iirnotch(w0=freq/(fs/2), Q=Q)\n",
    "        return filtfilt(b, a, data)\n",
    "\n",
    "    def dwt_denoise_reconstruct(self, signal, wavelet='db4', level=3, mode='soft'):\n",
    "        coeffs = pywt.wavedec(signal, wavelet=wavelet, level=level)\n",
    "        n = len(signal)\n",
    "        for i in range(1, len(coeffs)):\n",
    "            cd = coeffs[i]\n",
    "            sigma = np.median(np.abs(cd)) / 0.6745 if cd.size > 0 else 0.0\n",
    "            thresh = sigma * np.sqrt(2 * np.log(n)) if sigma > 0 else 0.0\n",
    "            coeffs[i] = pywt.threshold(cd, thresh, mode=mode)\n",
    "        rec = pywt.waverec(coeffs, wavelet=wavelet)\n",
    "        return np.asarray(rec[:n])\n",
    "\n",
    "    def read_input(self, input_path:str) -> pd.DataFrame:\n",
    "        if not os.path.exists(input_path):\n",
    "            raise FileNotFoundError(f\"Arquivo não encontrado: {input_path}\")\n",
    "        return pd.read_csv(input_path, sep=';')\n",
    "\n",
    "    def execute(self, input_path, output_path):\n",
    "        df = self.read_input(input_path)\n",
    "        df = df[df['code'] != -1]\n",
    "        df_other = df[[\"event\", \"device\", \"code\", \"size\"]].drop_duplicates(subset=[\"event\"])\n",
    "        df_pivot = df.pivot(index=\"event\", columns=\"channel\", values=\"data\").reset_index()\n",
    "        CHANNELS = [col for col in df_pivot.columns if col not in [\"event\"]]\n",
    "        df_pivot = df_pivot.merge(df_other, on=\"event\", how=\"inner\")\n",
    "        fs = 220\n",
    "        filtered = []\n",
    "        for _, row in df_pivot.iterrows():\n",
    "            filtered_row = {\n",
    "                'event': row['event'],\n",
    "                'device': row['device'],\n",
    "                'code': row['code'],\n",
    "                'size': row['size']\n",
    "            }\n",
    "            for channel in CHANNELS:\n",
    "                data = np.array([int(x) for x in row[channel].split(',')], dtype=float)\n",
    "                data = self.butterworth_highpass(data=data, cutoff=0.1, fs=fs, order=5)\n",
    "                data = self.notch_filter(data=data, fs=fs, freq=60.0, Q=30.0)\n",
    "                data = self.dwt_denoise_reconstruct(signal=data, wavelet='db4', level=3, mode='soft')\n",
    "                filtered_row[channel] = ','.join(map(lambda v: f\"{v:.6f}\", data))\n",
    "            filtered.append(filtered_row)\n",
    "        df_filtered = pd.DataFrame(filtered)\n",
    "        df_filtered.to_csv(output_path, index=False, sep=';')\n",
    "        print(\"Filtragem + DWT concluídas e CSV salvo em:\", output_path)\n",
    "\n",
    "if not os.path.exists(PREPROCESSED_MUSE_PATH):\n",
    "    Preprocessing().execute(\n",
    "        input_path=CSV_MUSE_PATH, \n",
    "        output_path=PREPROCESSED_MUSE_PATH\n",
    "    )\n",
    "else:\n",
    "    print(f\"Arquivo pré-processado já existe em: {PREPROCESSED_MUSE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Carregamento dos Dados para o Modelo\n",
    "\n",
    "Leitura do arquivo CSV pré-processado e transformação dos dados em um formato adequado para o treinamento do modelo de deep learning. Cada amostra é convertida em um array NumPy com shape `(n_amostras, TARGET_LEN, n_canais)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_csv(file_path):\n",
    "    CHANNELS = ['FP1', 'FP2', 'TP10', 'TP9']\n",
    "    TARGET_LEN = 440\n",
    "\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    df = df[df['code'] != -1]\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        channels_data = []\n",
    "        for ch in CHANNELS:\n",
    "            arr = np.array([float(x) for x in row[ch].split(',')])\n",
    "            if len(arr) > TARGET_LEN:\n",
    "                arr = arr[:TARGET_LEN]\n",
    "            elif len(arr) < TARGET_LEN:\n",
    "                arr = np.pad(arr, (0, TARGET_LEN - len(arr)), mode='constant')\n",
    "            channels_data.append(arr)\n",
    "\n",
    "        sample = np.stack(channels_data, axis=1)\n",
    "        X_list.append(sample)\n",
    "        y_list.append(int(row['code']))\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = ler_csv(PREPROCESSED_MUSE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Normalização e Divisão dos Dados\n",
    "\n",
    "Normalização dos dados utilizando Z-score seguido por `MinMaxScaler` para escalar os valores entre 0 e 1. Em seguida, os dados são divididos em conjuntos de treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: (23904, 440, 4), Validação: (2988, 440, 4), Teste: (2988, 440, 4)\n"
     ]
    }
   ],
   "source": [
    "def normalize(X_train: np.ndarray, X_val: np.ndarray, X_test: np.ndarray):\n",
    "    mu = X_train.mean(axis=(0, 1), keepdims=True)\n",
    "    sigma = X_train.std(axis=(0, 1), keepdims=True)\n",
    "    sigma[sigma == 0] = 1.0\n",
    "\n",
    "    X_train_z = (X_train - mu) / sigma\n",
    "    X_val_z   = (X_val - mu) / sigma\n",
    "    X_test_z  = (X_test - mu) / sigma\n",
    "\n",
    "    X_train_final = np.zeros_like(X_train_z)\n",
    "    X_val_final   = np.zeros_like(X_val_z)\n",
    "    X_test_final  = np.zeros_like(X_test_z)\n",
    "\n",
    "    n_channels = X_train.shape[2]\n",
    "\n",
    "    for ch in range(n_channels):\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        X_train_final[:, :, ch] = scaler.fit_transform(X_train_z[:, :, ch])\n",
    "        X_val_final[:, :, ch]   = scaler.transform(X_val_z[:, :, ch])\n",
    "        X_test_final[:, :, ch]  = scaler.transform(X_test_z[:, :, ch])\n",
    "\n",
    "    return X_train_final, X_val_final, X_test_final\n",
    "\n",
    "# Divisão dos dados\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Normalização\n",
    "X_train, X_val, X_test = normalize(X_train, X_val, X_test)\n",
    "\n",
    "print(f\"Treino: {X_train.shape}, Validação: {X_val.shape}, Teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Construção do Modelo\n",
    "\n",
    "Definição da arquitetura do modelo, que consiste em uma rede neural recorrente com camadas LSTM bidirecionais, dropout para regularização e camadas densas para a classificação final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761130253.336768   42157 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4000 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">880</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,566,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">880</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,937,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">484,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,390,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m, \u001b[38;5;34m880\u001b[0m)       │     \u001b[38;5;34m1,566,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m, \u001b[38;5;34m880\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m, \u001b[38;5;34m440\u001b[0m)       │     \u001b[38;5;34m1,937,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m, \u001b[38;5;34m440\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m, \u001b[38;5;34m220\u001b[0m)       │       \u001b[38;5;34m484,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m, \u001b[38;5;34m220\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m12,390,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,380,858</span> (62.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,380,858\u001b[0m (62.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,380,858</span> (62.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,380,858\u001b[0m (62.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model():\n",
    "    N_CHANNELS = 4\n",
    "    N_SAMPLES = 440\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=(N_SAMPLES, N_CHANNELS)),\n",
    "        Bidirectional(LSTM(N_SAMPLES, return_sequences=True)),\n",
    "        Dropout(0.1),\n",
    "        Bidirectional(LSTM(N_SAMPLES // 2, return_sequences=True)),\n",
    "        Dropout(0.1),\n",
    "        Bidirectional(LSTM(N_SAMPLES // 4, return_sequences=True)),\n",
    "        Dropout(0.1),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='elu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Treinamento do Modelo\n",
    "\n",
    "Treinamento do modelo com os dados preparados. São utilizados callbacks para `EarlyStopping` (interromper o treino se a performance não melhorar) e `ModelCheckpoint` (salvar o melhor modelo encontrado durante o treino)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 07:51:04.821124: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 10/374\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 407ms/step - accuracy: 0.0986 - loss: 14.1158"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m early_stop = EarlyStopping(\n\u001b[32m      2\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     patience=\u001b[32m10\u001b[39m,\n\u001b[32m      4\u001b[39m     restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m checkpoint = ModelCheckpoint(\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmelhor_modelo.keras\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     verbose=\u001b[32m0\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/ml-venv/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/ml-venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/ml-venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:221\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m ):\n\u001b[32m    220\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/ml-venv/lib/python3.13/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[39m, in \u001b[36m_OptionalImpl.has_value\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/ml-venv/lib/python3.13/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[39m, in \u001b[36moptional_has_value\u001b[39m\u001b[34m(optional, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    171\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionalHasValue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'melhor_modelo.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10, \n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Avaliação do Modelo\n",
    "\n",
    "Avaliação da performance do modelo treinado no conjunto de teste. São calculadas métricas como acurácia, precisão, recall e F1-score, além da exibição de um relatório de classificação detalhado por classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, X_test, y_test):\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro')\n",
    "    rec = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f\"\\n📊 Desempenho no conjunto de teste:\")\n",
    "    print(f\"Acurácia: {acc:.4f}\")\n",
    "    print(f\"Precisão (macro): {prec:.4f}\")\n",
    "    print(f\"Recall (macro): {rec:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nRelatório por classe:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "validate(model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Machine Learning)",
   "language": "python",
   "name": "ml-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
